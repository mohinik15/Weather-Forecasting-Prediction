{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28454880",
   "metadata": {},
   "source": [
    "# Weather Forecasting Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a547bb3",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "    \n",
    "Data Set Information:\n",
    "\n",
    "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "For more information, read [Cho et al, 2020].\n",
    "\n",
    "1.station - used weather station number: 1 to 25\n",
    "2.Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
    "3.Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
    "4.Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
    "5.LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
    "6.LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
    "7.LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
    "8.LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
    "9.LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
    "10.LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
    "11.LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
    "12.LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
    "13.LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
    "14.LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
    "15.LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
    "16.LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
    "17.LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
    "18.LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
    "19.lat - Latitude (Â°): 37.456 to 37.645\n",
    "20.lon - Longitude (Â°): 126.826 to 127.135\n",
    "21.DEM - Elevation (m): 12.4 to 212.3\n",
    "22.Slope - Slope (Â°): 0.1 to 5.2\n",
    "23.Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
    "24.Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
    "25.Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
    "\n",
    "Please note that there are two target variables here:\n",
    "\n",
    "-Next_Tmax: Next day maximum temperature\n",
    "-Next_Tmin: Next day minimum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/Dataset2/main/temperature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # checking the first 5 and last 5 rows of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a32704",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We had {} Rows and {} Columns before dropping duplicates.\".format(df.shape[0], df.shape[1]))\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"We have {} Rows and {} Columns after dropping duplicates.\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f98c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95abdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the statistical description of numeric datatype columns\n",
    "\n",
    "plt.figure(figsize = (15,9))\n",
    "sns.heatmap(round(df.describe()[1:].transpose(),2), linewidth = 2, annot= True, fmt = \".4f\", cmap=\"plasma\")\n",
    "plt.title(\"Satistical Report of Numerical Columns\")\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632d195",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f71bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "df['Day']=df['Date'].apply(lambda x:x.day)\n",
    "df['Month']=df['Date'].apply(lambda x:x.month)\n",
    "df['Year']=df['Date'].apply(lambda x:x.year)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9629d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install reverse_geocoder\n",
    "import reverse_geocoder as rg\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata=[]\n",
    "def reverse_geocoordinates(coordinates):\n",
    "    result = rg.search(coordinates)\n",
    "    return (result)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    coordinates = list(zip(df['lat'], df['lon']))\n",
    "    data = reverse_geocoordinates(coordinates)\n",
    "    geodata.append(data)\n",
    "\n",
    "geo_names = pd.DataFrame(geodata).transpose()\n",
    "print(geo_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601857ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State']=geo_names[0].apply(lambda x:x.get('admin1'))\n",
    "df['City']=geo_names[0].apply(lambda x:x.get('name'))\n",
    "df.drop(['lat','lon'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e019e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ff220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().to_frame(\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd518452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3066977",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.bar(df, figsize = (25,5), color=\"tab:green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in percentage:\\n\")\n",
    "for col in df:\n",
    "    percentage = np.round((df[col].isnull().sum()/df.shape[0])*100, 3)\n",
    "    print(col, \":\".format(), percentage, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We had {} Rows and {} Columns before dropping null values.\".format(df.shape[0], df.shape[1]))\n",
    "df.dropna(inplace=True)\n",
    "print(\"We have {} Rows and {} Columns after dropping null values.\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33988166",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['station', 'Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin', 'LDAPS_RHmax',\n",
    "       'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH',\n",
    "       'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', 'LDAPS_PPT1',\n",
    "       'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'DEM', 'Slope',\n",
    "       'Solar radiation', 'Next_Tmax', 'Next_Tmin', 'Day', 'Month', 'Year',\n",
    "       'State', 'City']\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c58d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_countplot(x):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.countplot(x)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "col1 = ['State', 'Year', 'City', 'Month', 'Day', 'station', 'DEM', 'Slope']\n",
    "\n",
    "for i in df[col1]:\n",
    "    print(\"Countplot for {} column:->\".format(i))\n",
    "    generate_countplot(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = [x for x in col if x not in col1]\n",
    "print(col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926111cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-pastel')\n",
    "\n",
    "for j in df[col2]:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    print(f\"Scatter plot for {j} column with respect to the rows covered ->\")\n",
    "    plt.scatter(df.index, df[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['station', 'Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin', 'LDAPS_RHmax', 'LDAPS_Tmax_lapse', \n",
    "                   'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH', 'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', \n",
    "                   'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'DEM', 'Slope', 'Solar radiation', 'Day', \n",
    "                   'Month', 'Year', 'State', 'City']\n",
    "\n",
    "label_columns = ['Next_Tmax', 'Next_Tmin']\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "for z in df[feature_columns]:\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.lineplot(x=df[z], y=label_columns[0], data=df)\n",
    "    sns.lineplot(x=df[z], y=label_columns[1], data=df)\n",
    "    plt.ylabel(\"Labels\")\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(['Next_Tmax', 'Next_Tmin'], fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bbe78",
   "metadata": {},
   "source": [
    "# Encoding the categorical object datatype columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "def ordinal_encode(df, column):\n",
    "    df[column] = oe.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "df=ordinal_encode(df, ['State', 'City'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5905c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of our data frame post encoding shows {} Rows and {} columns\\n\".format(df.shape[0], df.shape[1]))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fast')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=5, nrows=5, figsize=(15,20))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df[feature_columns].items():\n",
    "    sns.boxenplot(y=col, data=df, ax=ax[index], color=\"purple\")\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.4, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36facfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d74490",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=5, nrows=5, figsize=(15,20))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df[feature_columns].items():\n",
    "    sns.distplot(value, ax=ax[index], hist=False, color=\"r\", kde_kws={\"shade\": True})\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.4, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450516c1",
   "metadata": {},
   "source": [
    "# Using Z Score to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(zscore(df))\n",
    "threshold = 3\n",
    "df1 = df[(z<3).all(axis = 1)]\n",
    "\n",
    "print (\"Shape of the dataframe before removing outliers: \", df.shape)\n",
    "print (\"Shape of the dataframe after removing outliers: \", df1.shape)\n",
    "print (\"Percentage of data loss post outlier removal: \", (df.shape[0]-df1.shape[0])/df.shape[0]*100)\n",
    "\n",
    "df=df1.copy() # reassigning the changed dataframe name to our original dataframe name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7b7ce",
   "metadata": {},
   "source": [
    "# Using Log Transform to fix skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_columns:\n",
    "    if df.skew().loc[col]>0.55:\n",
    "        df[col]=np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ecb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34467ae",
   "metadata": {},
   "source": [
    "# Correlation using a Heatmap\n",
    "\n",
    "Positive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.\n",
    "\n",
    "Negative correlation - A correlation of –1 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-pastel')\n",
    "\n",
    "upper_triangle = np.triu(df.corr())\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f', \n",
    "            annot_kws={'size':8}, cmap=\"cubehelix_r\", mask=upper_triangle)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933e6e0",
   "metadata": {},
   "source": [
    "# Correlation Bar Plot comparing features with our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dfb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "df_corr = df.corr()\n",
    "plt.figure(figsize=(15,8))\n",
    "df_corr[label_columns[0]].sort_values(ascending=False).drop(label_columns[0]).plot.bar()\n",
    "plt.title(\"Correlation of Features vs Next_Tmax Label\\n\", fontsize=16)\n",
    "plt.xlabel(\"\\nFeatures List\", fontsize=14)\n",
    "plt.ylabel(\"Correlation Value with Next_Tmax\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78760ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "df_corr = df.corr()\n",
    "plt.figure(figsize=(15,8))\n",
    "df_corr[label_columns[1]].sort_values(ascending=False).drop(label_columns[1]).plot.bar()\n",
    "plt.title(\"Correlation of Features vs Next_Tmin Label\\n\", fontsize=16)\n",
    "plt.xlabel(\"\\nFeatures List\", fontsize=14)\n",
    "plt.ylabel(\"Correlation Value with Next_Tmin\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718a645",
   "metadata": {},
   "source": [
    "# Splitting the dataset into 2 variables namely 'X' and 'Y' for feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dcff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_columns]\n",
    "Y = df[label_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82742c1",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a955162",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X.head() # Displaying all the features after applying scaling technique to avoid bias output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce85277",
   "metadata": {},
   "source": [
    "# Finding the best random state for building Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "\n",
    "for i in range(1, 1000):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=i)\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    pred = lr.predict(X_test)\n",
    "    r2 = r2_score(Y_test, pred)\n",
    "    \n",
    "    if r2>maxAccu:\n",
    "        maxAccu=r2\n",
    "        maxRS=i\n",
    "\n",
    "print(\"Best R2 score is\", maxAccu,\"on Random State\", maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff9b32",
   "metadata": {},
   "source": [
    "# Feature importance for bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train, Y_train)\n",
    "importances = pd.DataFrame({'Features':X.columns, 'Importance':np.round(rf.feature_importances_,3)})\n",
    "importances = importances.sort_values('Importance', ascending=False).set_index('Features')\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b624025",
   "metadata": {},
   "source": [
    "# Machine Learning Model for Regression with Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0410f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Model Function\n",
    "\n",
    "def reg(model, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=43)\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting Y_test\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # RMSE - a lower RMSE score is better than a higher one\n",
    "    rmse = mean_squared_error(Y_test, pred, squared=False)\n",
    "    print(\"RMSE Score is:\", rmse)\n",
    "    \n",
    "    # R2 score\n",
    "    r2 = r2_score(Y_test, pred, multioutput='variance_weighted')*100\n",
    "    print(\"R2 Score is:\", r2)\n",
    "    \n",
    "    # Cross Validation Score\n",
    "    cv_score = (cross_val_score(model, X, Y, cv=5).mean())*100\n",
    "    print(\"Cross Validation Score:\", cv_score)\n",
    "    \n",
    "    # Result of r2 score minus cv score\n",
    "    result = r2 - cv_score\n",
    "    print(\"R2 Score - Cross Validation Score is\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43425111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "\n",
    "model=LinearRegression()\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "model=Ridge(alpha=1e-2, normalize=True)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9021087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "model=Lasso(alpha=1e-2, normalize=True, max_iter=1e5)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1601ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "model=DecisionTreeRegressor(criterion=\"poisson\", random_state=111)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14945a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "model=RandomForestRegressor(max_depth=2, max_features=\"sqrt\")\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Neighbors Regressor\n",
    "\n",
    "model=KNeighborsRegressor(n_neighbors=2, algorithm='kd_tree')\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Regressor\n",
    "\n",
    "model=ExtraTreesRegressor(n_estimators=200, max_features='sqrt', n_jobs=6)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f37c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "\n",
    "gbr=GradientBoostingRegressor()\n",
    "model=MultiOutputRegressor(estimator=gbr)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Regressor\n",
    "\n",
    "model=BaggingRegressor()\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVR\n",
    "\n",
    "lsvr=LinearSVR()\n",
    "model=MultiOutputRegressor(lsvr)\n",
    "reg(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2ad39",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning on the best Regression ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ebab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Linear SVR Regressor Model\n",
    "\n",
    "fmod_param = {'estimator__C' : [1.0, 2.0, 4.0],\n",
    "              'estimator__epsilon' : [0.0, 0.2, 0.4],\n",
    "              'estimator__max_iter' : [1000, 1500, 2000],\n",
    "              'estimator__random_state' : [43, 1111, 2222],\n",
    "              'estimator__loss' : ['epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_lsvr=LinearSVR()\n",
    "GSCV = GridSearchCV(MultiOutputRegressor(fin_lsvr), fmod_param, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea10fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906875",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_LSVR_Params = LinearSVR(C=4.0, epsilon=0.0, loss='squared_epsilon_insensitive', max_iter=1500, random_state=1111)\n",
    "Final_Model = MultiOutputRegressor(Final_LSVR_Params)\n",
    "Classifier = Final_Model.fit(X_train, Y_train)\n",
    "fmod_pred = Final_Model.predict(X_test)\n",
    "fmod_r2 = r2_score(Y_test, fmod_pred)*100\n",
    "print(\"R2 score for the Best Model is:\", fmod_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea9c34",
   "metadata": {},
   "source": [
    "# Saving the best Regression ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab74218",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"FinalModel_E10.pkl\"\n",
    "joblib.dump(Final_Model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
